{
 "metadata": {
  "name": "excercise"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# downloading mini_newsgroups\n",
      "import os\n",
      "import urllib\n",
      "import tarfile\n",
      "\n",
      "if not os.path.exists('mini_newsgroups.tar.gz'):\n",
      "    urllib.urlretrieve(\"http://kdd.ics.uci.edu/databases/20newsgroups/mini_newsgroups.tar.gz\", \"mini_newsgroups.tar.gz\")\n",
      "\n",
      "if not os.path.isdir(\"mini_newsgroups/\"):\n",
      "    tarfile.open(\"mini_newsgroups.tar.gz\", 'r:gz').extractall()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 320
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load\n",
      "import os\n",
      "import string\n",
      "\n",
      "# nltk stemmer\n",
      "from nltk.stem.snowball import EnglishStemmer\n",
      "from nltk import word_tokenize\n",
      "\n",
      "skip_headers = lambda txt: txt.split(\"\\n\\n\", 1)[1]\n",
      "ascii_text = lambda txt: filter(lambda x: x in string.printable, txt)\n",
      "tokenize = lambda txt: RegexpTokenizer(r'\\w+').tokenize(txt)\n",
      "stemmer = EnglishStemmer()\n",
      "stem = lambda terms: map(lambda term: stemmer.stem(term.replace(\"'\", '')), terms)\n",
      "\n",
      "doc_list = []\n",
      "y = []\n",
      "uniq_y = []\n",
      "labels = os.listdir('mini_newsgroups')\n",
      "for (i, label) in enumerate(labels):\n",
      "    uniq_y.append(i)\n",
      "    for fname in os.listdir(\"mini_newsgroups/%s\" % label):\n",
      "        with open('mini_newsgroups/%s/%s' % (label, fname)) as f:\n",
      "            y.append(i)\n",
      "            row_text = f.read()\n",
      "            stemmed_text = \" \".join(stem(tokenize(ascii_text(skip_headers(row_text)))))\n",
      "            doc_list.append(stemmed_text)\n",
      "\n",
      "y = np.array(y)\n",
      "\n",
      "doc_list[0]\n",
      "print labels\n",
      "print uniq_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['rec.autos', 'rec.motorcycles', 'comp.sys.mac.hardware', 'rec.sport.baseball', 'comp.sys.ibm.pc.hardware', 'talk.politics.misc', 'misc.forsale', 'sci.electronics', 'sci.med', 'rec.sport.hockey', 'talk.politics.guns', 'sci.crypt', 'talk.religion.misc', 'alt.atheism', 'comp.os.ms-windows.misc', 'comp.windows.x', 'talk.politics.mideast', 'sci.space', 'soc.religion.christian', 'comp.graphics']\n",
        "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
       ]
      }
     ],
     "prompt_number": 325
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print doc_list[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "path cantaloup srv cs cmu edu das news harvard edu noc near net howland reston an net zaphod mps ohio state edu menudo uh edu not for mail opug from opug academ01 mti itesm mx ing orlando puglies newsgroup rec auto subject is this a good price date 16 apr 93 18 28 41 gmt organ itesm campus monterrey line 25 messag id opug 734984921 mtecv2 nntp post host mtecv2 mti itesm mx hi everybodi i will buy a honda civic ex coup the dealer ask 12 750 for it includ a c instal but not includ stereo tax registr fee i live in mexico so i don t have time to go to a lot of dealer and compar their price the dealer is in mcallen tx is this a good price for that car if not how much should i pay for it pleas e mail asap if you don t want to post thank a lot orlando puglies opug mtecv2 mti itesm mx ___________________________________ orlando puglies n instituto tecnologico y de estudio superior de monterrey _________________ _________________ depto de informacion academica monterrey n l mexico 83 58 2000 ext 4113\n"
       ]
      }
     ],
     "prompt_number": 306
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create tf-idf matrix\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
      "tfidf_matrix = tfidf_vectorizer.fit_transform(doc_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 326
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(tfidf_matrix, y)\n",
      "print y_train.shape\n",
      "print y[400]\n",
      "print X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1500,)\n",
        "4\n",
        "(1500, 41631)\n"
       ]
      }
     ],
     "prompt_number": 332
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
      "\n",
      "classifier1 = MultinomialNB().fit(X_train, y_train)\n",
      "print classifier1.score(X_test, y_test)\n",
      "\n",
      "#classifier2 = KNeighborsClassifier(metric=\"cosine\", algorithm=\"kd_tree\").fit(X_train, y_train)\n",
      "classifier2 = KNeighborsClassifier(n_neighbors=50).fit(X_train, y_train)\n",
      "print classifier2.score(X_test, y_test)\n",
      "\n",
      "classifier3 = LinearSVC().fit(X_train, y_train)\n",
      "print classifier3.score(X_test, y_test)\n",
      "\n",
      "classifier4 = SGDClassifier().fit(X_train, y_train)\n",
      "print classifier4.score(X_test, y_test)\n",
      "\n",
      "print X_train[1,:].shape\n",
      "print y_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.686\n",
        "0.598"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.886"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.87"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(1, 41631)\n",
        "(1500,)\n"
       ]
      }
     ],
     "prompt_number": 333
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PCA\n",
      "from sklearn.decomposition import PCA\n",
      "X = tfidf_matrix.todense()\n",
      "pca = PCA(n_components=100).fit(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_pca = pca.transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_pca, y)\n",
      "classifier2 = KNeighborsClassifier(metric=\"cosine\", algorithm=\"brute\", n_neighbors=50).fit(X_train, y_train)\n",
      "print classifier2.score(X_test, y_test)\n",
      "print X_pca.shape\n",
      "\n",
      "classifier3 = LinearSVC().fit(X_train, y_train)\n",
      "print classifier3.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.59\n",
        "(2000, 100)\n",
        "0.664"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "document_distances = (X_train * X_train.T)\n",
      "print X_train.shape\n",
      "print document_distances.shape\n",
      "document_distances[1,2]\n",
      "\n",
      "from sklearn.metrics.pairwise import linear_kernel\n",
      "cosine_similarities = linear_kernel(tfidf_matrix[2,:], tfidf_matrix).flatten() # let's look at similarity to the very first document\n",
      "related_docs_indices = cosine_similarities.argsort()[:-len(doc_list)-1:-1] #what is the order of most to least similar?\n",
      "\n",
      "\n",
      "print y[related_docs_indices[0:10]]\n",
      "print cosine_similarities[related_docs_indices] # what are the cosine distances?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1500, 50644)\n",
        "(1500, 1500)\n",
        "[ 0  0  0  0  5  0  0  5 11 18]\n",
        "[ 1.          0.23625337  0.18393705 ...,  0.00819934  0.00716811\n",
        "  0.00331452]\n"
       ]
      }
     ],
     "prompt_number": 59
    }
   ],
   "metadata": {}
  }
 ]
}